{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1db47f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto reload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Set the matplotlib backend\n",
    "%matplotlib widget\n",
    "\n",
    "import hydra\n",
    "from drone_rl_school.agents.dqn import DQNAgent, ReplayBuffer\n",
    "from drone_rl_school.agents.pid import PIDAgent\n",
    "from drone_rl_school.envs.point_mass_env import PointMassEnv\n",
    "from drone_rl_school.agents.q_learning import QLearningAgent\n",
    "from drone_rl_school.train.train import train\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from omegaconf import OmegaConf\n",
    "import os\n",
    "import subprocess\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba3b4ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hydra.initialize()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Hydra\n",
    "hydra.initialize(config_path=\"../configs\", version_base=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19a395bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the config\n",
    "cfg = hydra.compose(config_name=\"config\")\n",
    "\n",
    "# Prepare the logging directory\n",
    "commit = subprocess.check_output([\"git\", \"rev-parse\", \"HEAD\"]).decode().strip()\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "exp_name  = f\"{timestamp}_{cfg.agent.type}_{commit[:7]}\"\n",
    "log_dir   = os.path.join(cfg.run.log_root, exp_name)\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Save a frozen copy of the config\n",
    "with open(os.path.join(log_dir, \"config.yaml\"), \"w\") as fp:\n",
    "    fp.write(OmegaConf.to_yaml(cfg))\n",
    "\n",
    "# Create the actual tensorboard logger\n",
    "writer = SummaryWriter(log_dir)    # run in terminal: \"tensorboard --logdir=runs\", address: http://localhost:6006\n",
    "\n",
    "# Set up the environment\n",
    "random_seed = cfg.env.random_number_generator_seed\n",
    "env = PointMassEnv(cfg, random_seed)\n",
    "\n",
    "next_episode_to_train = 0\n",
    "best_score = float('-inf')\n",
    "\n",
    "buffer = None\n",
    "\n",
    "# Define the agent\n",
    "if cfg.agent.type == 'dqn':    \n",
    "    agent = DQNAgent(cfg)\n",
    "    buffer = ReplayBuffer(cfg)\n",
    "elif cfg.agent.type == 'q_learning':\n",
    "    agent = QLearningAgent(cfg)\n",
    "elif cfg.agent.type == 'pid':\n",
    "    agent = PIDAgent(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e21b5fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\code\\drone_rl_school\\drone_rl_school\\agents\\dqn.py:35: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:257.)\n",
      "  torch.tensor(o, dtype=torch.float32, device=self.device),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 to 100 \t                   Mean of Metric: -4.71\n",
      "Episode 100 to 200 \t                   Mean of Metric: -1.32\n"
     ]
    }
   ],
   "source": [
    "# Run one training loop\n",
    "last_episode, rewards, best_score = train(agent, env, writer, cfg,\n",
    "                start_episode=next_episode_to_train, best_score=best_score,\n",
    "                buffer=buffer)\n",
    "next_episode_to_train = last_episode + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30846f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated Episode    Total Reward: 9923.080532656748\n",
      "Simulated Episode    Total Reward: 9844.17929813497\n",
      "Simulated Episode    Total Reward: 9832.495997897224\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "PointMassEnv.animate() missing 1 required positional argument: 'trajectory_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Run a simulation\u001b[39;00m\n\u001b[32m      2\u001b[39m trajectories = [env.simulate(agent) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m3\u001b[39m)]\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43manimate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrajectories\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgoal\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: PointMassEnv.animate() missing 1 required positional argument: 'trajectory_names'"
     ]
    }
   ],
   "source": [
    "# Run a simulation\n",
    "trajectories = [env.simulate(agent) for _ in range(3)]\n",
    "env.animate(trajectories, env.goal, trajectory_names=['dqn'] * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6093ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a simulation in comparison to a simple pid controller\n",
    "sim_seed = np.random.randint(100000)\n",
    "pid_config = hydra.compose(config_name=\"config\", overrides=[\"agent= pid\"])\n",
    "trajectories = [PointMassEnv(cfg, sim_seed).simulate(agent), PointMassEnv(pid_config, sim_seed).simulate(PIDAgent(pid_config))]\n",
    "env.animate(trajectories, env.goal, trajectory_names=['dqn', 'pid'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
